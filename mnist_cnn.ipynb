{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classifier using CNN\n",
    "\n",
    "## Authors:\n",
    "\n",
    "Nicola Rocco de Luna Pedulla - nrlp\n",
    "\n",
    "\n",
    "Renan de Freitas Lins - rfl3\n",
    "\n",
    "Ricardo Rossiter Barioni - rrb\n",
    "\n",
    "Victor Miranda de Melo - vmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firstly, import the required dependencies\n",
    "\n",
    "GPU is not being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepLearningPython35.network3 import load_data_shared, Network, ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer, ReLU, size\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From mnist_loader, gather the training, validation and test data\n",
    "Each data is structured as a tuple of two elements, as follows: The first element of the tuple contains information about the image, while the second element contains the label of that tuple.\n",
    "\n",
    "In the case of this dataset, the label tells the number (0 to 9) that the image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_shared()\n",
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For smaller tests, it was created a subset of the training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subset(data, l):\n",
    "    \n",
    "    x =  data[0].get_value(borrow=True)[:l]\n",
    "    y = data[1].eval()[:l]\n",
    "\n",
    "    shared_x = theano.shared( np.asarray(x, dtype=theano.config.floatX), borrow=True)\n",
    "    shared_y = theano.shared( np.asarray(y, dtype=theano.config.floatX), borrow=True)\n",
    "    return (shared_x, T.cast(shared_y, \"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training_data_subset = get_subset(training_data, 2000)\n",
    "test_data_subset = get_subset(test_data, 2000)\n",
    "validation_data_subset = get_subset(validation_data, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.46%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.20%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 97.69%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.55%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.92%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.60%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.78%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.32%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.99%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.30%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.69%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.58%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.62%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.35%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.29%\n",
      "Finished training network.\n",
      "Best validation accuracy of 98.69% obtained at iteration 34999\n",
      "Corresponding test accuracy of 98.58%\n"
     ]
    }
   ],
   "source": [
    "net = Network([\n",
    "    ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28),\n",
    "                  filter_shape=(20, 1, 5, 5),\n",
    "                  poolsize=(2, 2),\n",
    "                  activation_fn=ReLU),\n",
    "    ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12),\n",
    "                  filter_shape=(40, 20, 5, 5),\n",
    "                  poolsize=(2, 2),\n",
    "                  activation_fn=ReLU),\n",
    "    FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "    SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 10, mini_batch_size, 0.03, validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the total accuracy of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(net, data):\n",
    "    num_test_batches = int(size(data)/net.mini_batch_size)\n",
    "    v = [net.test_mb_predictions(i) for i in range(num_test_batches)]\n",
    "    pair = zip(np.concatenate(v),list(data[1].eval()))\n",
    "    return np.mean([x == y for x,y in pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ( 98.07% )\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', '(', '{0:.2f}'.format(100*get_accuracy(net,test_data))+'%',')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the accuracy for each of the possible labels (from 0 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 : 967 / 980 ( 98.67% )\n",
      "label 1 : 1115 / 1135 ( 98.24% )\n",
      "label 2 : 1020 / 1032 ( 98.84% )\n",
      "label 3 : 994 / 1010 ( 98.42% )\n",
      "label 4 : 930 / 982 ( 94.70% )\n",
      "label 5 : 888 / 892 ( 99.55% )\n",
      "label 6 : 943 / 958 ( 98.43% )\n",
      "label 7 : 1021 / 1028 ( 99.32% )\n",
      "label 8 : 947 / 974 ( 97.23% )\n",
      "label 9 : 982 / 1009 ( 97.32% )\n"
     ]
    }
   ],
   "source": [
    "test_data_y = test_data[1].eval()\n",
    "\n",
    "num_test_batches = int(size(test_data)/net.mini_batch_size)\n",
    "v = [net.test_mb_predictions(i) for i in range(num_test_batches)]\n",
    "\n",
    "pair = list(zip(np.concatenate(v),list(test_data[1].eval())))\n",
    "\n",
    "accuracies = [[x == y for x,y in pair if y == i ] for i in range(10)]\n",
    "\n",
    "for i,val in enumerate(accuracies):\n",
    "    print('label', i, ':', sum(val), '/', len(val), '(', '{0:.2f}'.format(100*np.mean(val))+ '%', ')')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
