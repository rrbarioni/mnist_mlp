{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classifier using MLP\n",
    "\n",
    "## Authors:\n",
    "\n",
    "Nicola Rocco de Luna Pedulla - nrlp\n",
    "\n",
    "\n",
    "Renan de Freitas Lins - rfl3\n",
    "\n",
    "Ricardo Rossiter Barioni - rrb\n",
    "\n",
    "Victor Miranda de Melo - vmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firstly, import the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeepLearningPython35.mnist_loader as mnist_loader\n",
    "import DeepLearningPython35.network as network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From mnist_loader, gather the training, validation and test data\n",
    "Each data is structured as a tuple of two elements, as follows: The first element of the tuple contains information about the image, while the second element contains the label of that tuple.\n",
    "\n",
    "In the case of this dataset, the label tells the number (0 to 9) that the image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data = list(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From network, perform MLP training\n",
    "\n",
    "We created a MLP with three layers:\n",
    "\n",
    "The first layers contains 784 neurons, once all input images has a 28 rows and 28 columns (28x28 = 784);\n",
    "\n",
    "The second layer contains 30 neurons;\n",
    "\n",
    "The last layer contains 10 neurons, so each neuron is responsible for a possible number result (0 to 9), which we want to evaluate.\n",
    "\n",
    "For training, we set a total of 30 epoch, with each mini-batch having 10 images, and with a learning rate of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "Epoch 10 complete\n",
      "Epoch 11 complete\n",
      "Epoch 12 complete\n",
      "Epoch 13 complete\n",
      "Epoch 14 complete\n",
      "Epoch 15 complete\n",
      "Epoch 16 complete\n",
      "Epoch 17 complete\n",
      "Epoch 18 complete\n",
      "Epoch 19 complete\n",
      "Epoch 20 complete\n",
      "Epoch 21 complete\n",
      "Epoch 22 complete\n",
      "Epoch 23 complete\n",
      "Epoch 24 complete\n",
      "Epoch 25 complete\n",
      "Epoch 26 complete\n",
      "Epoch 27 complete\n",
      "Epoch 28 complete\n",
      "Epoch 29 complete\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation of the trained network, divide the dataset by the image's label.\n",
    "\n",
    "In this case, the whole test dataset is divided into ten subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(test_data)\n",
    "test_data_by_labels = [[element for element in test_data if element[1] == i] \\\n",
    "                        for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each subset, its accuracy is calculated. For that, the image is used as a input into the network, so that we can compare the net's output with the ground-truth.\n",
    "\n",
    "With that, we can calculate the accuracy of the network for each of the ten subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 970 / 980 ( 98.98% )\n",
      "label 1: 1120 / 1135 ( 98.68% )\n",
      "label 2: 965 / 1032 ( 93.51% )\n",
      "label 3: 932 / 1010 ( 92.28% )\n",
      "label 4: 938 / 982 ( 95.52% )\n",
      "label 5: 840 / 892 ( 94.17% )\n",
      "label 6: 2 / 958 ( 0.21% )\n",
      "label 7: 968 / 1028 ( 94.16% )\n",
      "label 8: 909 / 974 ( 93.33% )\n",
      "label 9: 939 / 1009 ( 93.06% )\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_data_by_labels)):\n",
    "    curr_label_eval = net.evaluate(test_data=test_data_by_labels[i])\n",
    "    print('label ' + str(i) + ': ' + \\\n",
    "          str(curr_label_eval) + ' / ' + str(len(test_data_by_labels[i])) + \\\n",
    "          ' ( ' + \\\n",
    "          '{0:.2f}'.format(100 * curr_label_eval/len(test_data_by_labels[i])) + \\\n",
    "          '% )')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
